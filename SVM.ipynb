{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T14:04:54.088727Z",
     "start_time": "2025-03-11T14:04:54.078025Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "# Apply metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_score, recall_score, roc_auc_score\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:04:55.344361Z",
     "start_time": "2025-03-11T14:04:55.326746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('data/processed-data.csv')\n",
    "df = pd.get_dummies(df, columns=['ph', 'rainfall'])\n",
    "\n",
    "# split the dataframe into features (x) and labels (y)\n",
    "x = df.drop(columns = ['label'])\n",
    "y = df['label']"
   ],
   "id": "b4f108232c727e5",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:04:56.815743Z",
     "start_time": "2025-03-11T14:04:56.802228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the data to 90-10 where 90% is for training and testing while the remaining 10% is for unseen data\n",
    "x_seen, x_unseen, y_seen, y_unseen = train_test_split(x, y, test_size = 0.20, random_state = 42)"
   ],
   "id": "59fe383331a65ed6",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:04:59.960539Z",
     "start_time": "2025-03-11T14:04:59.944376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='poly', degree=3, C=1.0, gamma='scale', decision_function_shape='ovr', probability=True)\n",
    "\n",
    "# instantiate a 10-fold cross-validation\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 42)"
   ],
   "id": "f27572f1f3e9621b",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:07:20.419246Z",
     "start_time": "2025-03-11T14:07:20.140308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Perform 10-Fold Cross Validation on the training dataset (x_seen, y_seen)\n",
    "y_pred_cv = cross_val_predict(model, x_seen, y_seen, cv=kf)\n",
    "\n",
    "y_proba_cv = cross_val_predict(model, x_seen, y_seen, cv = kf, method = 'predict_proba')"
   ],
   "id": "3992a09b2c7ac000",
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of cross_val_score must be a str among {'neg_root_mean_squared_error', 'neg_root_mean_squared_log_error', 'roc_auc_ovr', 'precision_macro', 'explained_variance', 'homogeneity_score', 'neg_negative_likelihood_ratio', 'normalized_mutual_info_score', 'jaccard', 'fowlkes_mallows_score', 'recall_macro', 'completeness_score', 'f1_samples', 'average_precision', 'precision_weighted', 'matthews_corrcoef', 'neg_brier_score', 'neg_mean_squared_log_error', 'f1', 'neg_mean_gamma_deviance', 'recall_weighted', 'neg_log_loss', 'neg_max_error', 'neg_mean_absolute_percentage_error', 'precision_micro', 'recall_samples', 'roc_auc_ovo_weighted', 'neg_mean_poisson_deviance', 'top_k_accuracy', 'f1_macro', 'rand_score', 'precision', 'v_measure_score', 'positive_likelihood_ratio', 'adjusted_rand_score', 'accuracy', 'neg_mean_squared_error', 'jaccard_macro', 'roc_auc_ovr_weighted', 'd2_absolute_error_score', 'jaccard_micro', 'neg_mean_absolute_error', 'r2', 'recall_micro', 'balanced_accuracy', 'jaccard_samples', 'jaccard_weighted', 'f1_micro', 'adjusted_mutual_info_score', 'roc_auc', 'mutual_info_score', 'recall', 'f1_weighted', 'neg_median_absolute_error', 'roc_auc_ovo', 'precision_samples'}, a callable or None. Got ['accuracy', 'precision', 'recall'] instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidParameterError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Perform 10-Fold Cross Validation on the training dataset (x_seen, y_seen)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m y_pred_cv \u001B[38;5;241m=\u001B[39m cross_val_predict(model, x_seen, y_seen, cv\u001B[38;5;241m=\u001B[39mkf)\n\u001B[1;32m----> 5\u001B[0m istipin \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_seen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_seen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrecall\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(istipin)\n\u001B[0;32m      8\u001B[0m y_proba_cv \u001B[38;5;241m=\u001B[39m cross_val_predict(model, x_seen, y_seen, cv \u001B[38;5;241m=\u001B[39m kf, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredict_proba\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Midterm-Summative-Activity\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:206\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    203\u001B[0m to_ignore \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcls\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    204\u001B[0m params \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m params\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m to_ignore}\n\u001B[1;32m--> 206\u001B[0m \u001B[43mvalidate_parameter_constraints\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameter_constraints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaller_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__qualname__\u001B[39;49m\n\u001B[0;32m    208\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    212\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    213\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    214\u001B[0m         )\n\u001B[0;32m    215\u001B[0m     ):\n",
      "File \u001B[1;32m~\\Desktop\\Midterm-Summative-Activity\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001B[0m, in \u001B[0;36mvalidate_parameter_constraints\u001B[1;34m(parameter_constraints, params, caller_name)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     constraints_str \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;28mstr\u001B[39m(c)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mconstraints[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     95\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     96\u001B[0m     )\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m InvalidParameterError(\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_name\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m parameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcaller_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_val\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    101\u001B[0m )\n",
      "\u001B[1;31mInvalidParameterError\u001B[0m: The 'scoring' parameter of cross_val_score must be a str among {'neg_root_mean_squared_error', 'neg_root_mean_squared_log_error', 'roc_auc_ovr', 'precision_macro', 'explained_variance', 'homogeneity_score', 'neg_negative_likelihood_ratio', 'normalized_mutual_info_score', 'jaccard', 'fowlkes_mallows_score', 'recall_macro', 'completeness_score', 'f1_samples', 'average_precision', 'precision_weighted', 'matthews_corrcoef', 'neg_brier_score', 'neg_mean_squared_log_error', 'f1', 'neg_mean_gamma_deviance', 'recall_weighted', 'neg_log_loss', 'neg_max_error', 'neg_mean_absolute_percentage_error', 'precision_micro', 'recall_samples', 'roc_auc_ovo_weighted', 'neg_mean_poisson_deviance', 'top_k_accuracy', 'f1_macro', 'rand_score', 'precision', 'v_measure_score', 'positive_likelihood_ratio', 'adjusted_rand_score', 'accuracy', 'neg_mean_squared_error', 'jaccard_macro', 'roc_auc_ovr_weighted', 'd2_absolute_error_score', 'jaccard_micro', 'neg_mean_absolute_error', 'r2', 'recall_micro', 'balanced_accuracy', 'jaccard_samples', 'jaccard_weighted', 'f1_micro', 'adjusted_mutual_info_score', 'roc_auc', 'mutual_info_score', 'recall', 'f1_weighted', 'neg_median_absolute_error', 'roc_auc_ovo', 'precision_samples'}, a callable or None. Got ['accuracy', 'precision', 'recall'] instead."
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:05:15.898910Z",
     "start_time": "2025-03-11T14:05:15.868923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute Metrics for Cross Validation for Seen data\n",
    "conf_matrix = confusion_matrix(y_seen, y_pred_cv)\n",
    "accuracy = accuracy_score(y_seen, y_pred_cv)\n",
    "precision = precision_score(y_seen, y_pred_cv, average='weighted')  # Use 'weighted' for multi-class\n",
    "recall = recall_score(y_seen, y_pred_cv, average='weighted')\n",
    "\n",
    "roc_auc = roc_auc_score(y_seen, y_proba_cv, multi_class = 'ovr')\n",
    "\n",
    "# Print Results\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n"
   ],
   "id": "fe0a743de89b9a9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[74  0  0  1  0  0  4  0  0  0]\n",
      " [ 0 87  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 85  0  0  0  0  0  0  0]\n",
      " [ 1  2  0 64  0  0  1  0  9  0]\n",
      " [ 0  0  0  0 73  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 79  0  0  0  0]\n",
      " [ 0  4  0  0  0  1 82  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 75  0  0]\n",
      " [ 0  0  0 42  0  0  0  0 38  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 78]]\n",
      "Accuracy: 0.91875\n",
      "Precision: 0.9263539865888063\n",
      "Recall: 0.91875\n",
      "ROC-AUC Score: 0.9935852260756348\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:05:34.788435Z",
     "start_time": "2025-03-11T14:05:34.754298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train now the data based on 90% since it will be the basis on how it will behave for unseen data\n",
    "model.fit(x_seen, y_seen);"
   ],
   "id": "51ba7c1d9f3875dc",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T14:08:56.184659Z",
     "start_time": "2025-03-11T14:08:56.153291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test now the model based on the actual data (unseen na 10%)\n",
    "\n",
    "y_unseen_pred = model.predict(x_unseen);\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_unseen, y_unseen_pred)\n",
    "accuracy = accuracy_score(y_unseen, y_unseen_pred)\n",
    "precision = precision_score(y_unseen, y_unseen_pred, average='weighted')  # Use 'weighted' for multi-class\n",
    "recall = recall_score(y_unseen, y_unseen_pred, average='weighted')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ],
   "id": "41fa5079d414832a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[21  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 15  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  1  0  5  0]\n",
      " [ 0  0  0  0 27  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 21  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  0  0 10  0  0  0  0 10  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 22]]\n",
      "Accuracy: 0.92\n",
      "Precision: 0.919431216931217\n",
      "Recall: 0.92\n"
     ]
    }
   ],
   "execution_count": 100
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
